# Purpose:
# This file contains variables needed to deploy and run Spark (version without Hadoop files).

# note: spark_ver is passed in from the calling script
spark_version: "{{ spark_ver }}"

spark_base: /opt/spark
spark_home: "{{ spark_base }}/{{ spark_version }}"
spark_compressed: /opt/compressed

spark_file_extracted: spark-{{ spark_version }}-bin-without-hadoop
spark_file: "{{ spark_file_extracted }}.tgz"
spark_file_checksum_md5: "{{ spark_file }}.md5"

spark_user_name:  spark
spark_user_group: "{{ spark_user_name }}"
spark_user_pwd:  "{{ spark_user_name }}"
spark_user_home: /home/{{ spark_user_name }}

# hard-code java_home to the symlink java-1.8.0-openjdk-adm46
# to ensure the default-jdk doesn't inadvertenly update to java 9
java_home: /usr/lib/jvm/java-1.8.0-openjdk-amd64

spark_conf_dir: "{{ spark_home }}/conf"
spark_defaults_conf_file_name: spark-defaults.conf
spark_defaults_conf_file_path: "{{ spark_conf_dir }}/{{ spark_defaults_conf_file_name }}"
spark_env_file_name: spark-env.sh
spark_env_file_path: "{{ spark_conf_dir }}/{{ spark_env_file_name }}"
spark_master_node: head

path: "{{ spark_home }}/bin:{{ spark_home }}/sbin:{{ java_home }}/bin:{{ java_home }}/bin"

spark_defaults_conf_file_list:
  - echo "" >> {{ spark_defaults_conf_file_path }};
  - echo "" >> {{ spark_defaults_conf_file_path }};
  - echo \# Set via Ansible playbook >> {{ spark_defaults_conf_file_path }};
  - echo spark.master  spark://{{ spark_master_node }}:7077 >> {{ spark_defaults_conf_file_path }}

# note: in spark 1 SPARK_MASTER_HOST was SPARK_MASTER_IP
spark_env_file_list:
  - echo "" >> {{ spark_env_file_path }};
  - echo "" >> {{ spark_env_file_path }};
  - echo \# Set via Ansible playbook >> {{ spark_env_file_path }};
  - echo SPARK_MASTER_HOST={{ spark_master_node }} >> {{ spark_env_file_path }}


