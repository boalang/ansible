# Purpose:
# This file contains variables needed to deploy and run Hadoop.

hadoop_base: /opt/hadoop
hadoop_install: "{{ hadoop_base }}/{{ hadoop_version }}"
hadoop_file: hadoop-{{ hadoop_version }}.tar.gz
hadoop_compressed: /opt/compressed
hadoop_user_name:  hadoop
hadoop_user_group: "{{ hadoop_user_name }}"
hadoop_user_pwd:  "{{ hadoop_user_name }}"
hadoop_conf_dir: "{{ hadoop_base }}/{{ hadoop_version }}_conf_in_use"
hadoop_conf_master_dir: "{{ hadoop_base }}/{{ hadoop_version }}_conf_master"
hadoop_default_conf_dir:  conf
hadoop_data_base_dir: /data
hadoop_env_file: "{{ hadoop_conf_dir }}/hadoop-env.sh"
hadoop_home: /home/{{ hadoop_user_name }}
hadoop_env_vars_profile_d_file:  /etc/profile.d/hadoop-{{ hadoop_version }}-env.sh

# these two directories only need to be on one drive, so they'll be coded to /data1, as it should always exist
hadoop_HADOOP_LOG_DIR: "{{ hadoop_data_base_dir }}1/{{ hadoop_version }}/logs"
hadoop_HADOOP_PID_DIR: "{{ hadoop_data_base_dir }}1/{{ hadoop_version }}/pids"
mapred_system_dir: /data1/{{ hadoop_version }}/mapred/system

hadoop_name_node: head
hadoop_secondary_name_node: head
hadoop_data_node_base_name: boa-
hadoop_num_data_node: 15
hadoop_num_drives_per_node: 2

path: "{{ hadoop_install }}/bin:{{ hadoop_install }}/sbin:{{ java_home }}/bin:{{ java_home }}/bin"

# hard-code java_home to the symlink java-1.8.0-openjdk-adm46
# to ensure the default-jdk doesn't inadvertenly update to java 9
java_home: /usr/lib/jvm/java-1.8.0-openjdk-amd64

hadoop_dfs_name_dir: name
hadoop_dfs_data_dir: hdfs-data
hadoop_fs_checkpoint_dir: name-secondary
hadoop_mapred_local_dir: "mapred/local"
hadoop_mapred_system_dir: "mapred/system"

# This dictionary will facilitate adding relevant export statements at the bottom of hadoop-env.sh
# When using the with_dict attribute with the file module, the module will automatically iterate over 
# all of the elements in the dictionary.

hadoop_env_dict:
# java home
  java_new_line:  echo  >> {{ hadoop_env_file }};
  java_comment:  echo \# Setting JAVA_HOME via Ansible playbook >> {{ hadoop_env_file }};
  java_export:  echo export JAVA_HOME={{ java_home }} >> {{ hadoop_env_file }}
# HADOOP_INSTALL=/opt/hadoop/version
  install_new_line:  echo  >> {{ hadoop_env_file }};
  install_comment:  echo \# Setting HADOOP_INSTALL via Ansible playbook >> {{ hadoop_env_file }};
  install_export:  echo export HADOOP_INSTALL={{ hadoop_install }} >> {{ hadoop_env_file }}
# HADOOP_CONF_DIR=/opt/hadoop/conf_version
  conf_new_line:  echo  >> {{ hadoop_env_file }};
  conf_comment:  echo \# Setting HADOOP_CONF_DIR via Ansible playbook >> {{ hadoop_env_file }};
  conf_export:  echo export HADOOP_CONF_DIR={{ hadoop_conf_dir }} >> {{ hadoop_env_file }}
# HADOOP_LOG_DIR=/data1/version/logs
  logs_new_line:  echo  >> {{ hadoop_env_file }};
  logs_comment:  echo \# Setting HADOOP_LOG_DIR via Ansible playbook >> {{ hadoop_env_file }};
  logs_export:  echo export HADOOP_LOG_DIR={{ hadoop_HADOOP_LOG_DIR }} >> {{ hadoop_env_file }}
# HADOOP_PID_DIR=/data1/version/pids
  pids_new_line:  echo  >> {{ hadoop_env_file }};
  pids_comment:  echo \# Setting HADOOP_PID_DIR via Ansible playbook >> {{ hadoop_env_file }};
  pids_export:  echo export HADOOP_PID_DIR={{ hadoop_HADOOP_PID_DIR }} >> {{ hadoop_env_file }}


protobuf_java_250_md5_name: protobuf-java-2.5.0.jar.md5
protobuf_java_250_md5_path: http://central.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/
protobuf_java_250_md5_url: http://central.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/{{ protobuf_java_250_md5_name }}
protobuf_java_250_jar_url: http://central.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar
